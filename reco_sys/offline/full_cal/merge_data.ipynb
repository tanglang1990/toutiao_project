{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 合并数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/toutiao_project/reco_sys\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# 如果当前代码文件运行测试需要加入修改路径，避免出现后导包问题\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "sys.path.insert(0, os.path.join(BASE_DIR))\n",
    "print(BASE_DIR)\n",
    "PYSPARK_PYTHON = \"/miniconda2/envs/reco_sys/bin/python\"\n",
    "# 当存在多个版本时，不指定很可能会导致出错\n",
    "os.environ[\"PYSPARK_PYTHON\"] = PYSPARK_PYTHON\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = PYSPARK_PYTHON\n",
    "from offline import SparkSessionBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OriginArticleData(SparkSessionBase):\n",
    "    \n",
    "    SPARK_APP_NAME = \"mergeArticle\"\n",
    "    SPARK_URL = \"spark://hadoop-master:7077\"\n",
    "\n",
    "    ENABLE_HIVE_SUPPORT = True\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.spark = self._create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa = OriginArticleData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行文章 前两个表 的合并\n",
    "oa.spark.sql(\"use toutiao\")\n",
    "# news_article_basic 与news_article_content, article_id\n",
    "titlce_content = oa.spark.sql(\"select a.article_id, a.channel_id, a.title, b.content from news_article_basic a inner join news_article_content b on a.article_id=b.article_id where a.article_id=116636\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+--------------------+\n",
      "|article_id|channel_id|          title|             content|\n",
      "+----------+----------+---------------+--------------------+\n",
      "|    116636|        18|动态再平衡投资策略历史数据回测|<p>赚钱是个俗气的话题，但又是人...|\n",
      "+----------+----------+---------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titlce_content.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行title_content 与 文章频道名称合并\n",
    "titlce_content.registerTempTable('temptable')\n",
    "\n",
    "channel_title_content = oa.spark.sql(\"select t.*, n.channel_name from temptable t left join news_channel n on t.channel_id=n.channel_id\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+--------------------+------------+\n",
      "|article_id|channel_id|          title|             content|channel_name|\n",
      "+----------+----------+---------------+--------------------+------------+\n",
      "|    116636|        18|动态再平衡投资策略历史数据回测|<p>赚钱是个俗气的话题，但又是人...|      python|\n",
      "+----------+----------+---------------+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_title_content.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并三个内容到一个字符串\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "sentence_df = channel_title_content.select(\"article_id\", \"channel_id\", \"channel_name\", \"title\", \"content\", \n",
    "                            F.concat_ws(',', \n",
    "                                       channel_title_content.channel_name,\n",
    "                                       channel_title_content.title,\n",
    "                                       channel_title_content.content).alias('sentence'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------+---------------+--------------------+--------------------+\n",
      "|article_id|channel_id|channel_name|          title|             content|            sentence|\n",
      "+----------+----------+------------+---------------+--------------------+--------------------+\n",
      "|    116636|        18|      python|动态再平衡投资策略历史数据回测|<p>赚钱是个俗气的话题，但又是人...|python,动态再平衡投资策略历...|\n",
      "+----------+----------+------------+---------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence_df.show()\n",
    "# sentence_df.write.insertInto(\"article_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 文章分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------+--------------------+--------------------+--------------------+\n",
      "|article_id|channel_id|channel_name|               title|             content|            sentence|\n",
      "+----------+----------+------------+--------------------+--------------------+--------------------+\n",
      "|     12237|        18|      python|想学习区块链？那就用 Python...|<div id=\"article_...|python,想学习区块链？那就用...|\n",
      "|     12238|        18|      python|鲜为人知的 Python 语法 使...|<p>所有人（好吧，不是所有人）都...|python,鲜为人知的 Pyth...|\n",
      "|     12243|        18|      python|手把手教你写网络爬虫（4）：Scr...|<div id=\"cnblogs_...|python,手把手教你写网络爬虫...|\n",
      "|     12245|        18|      python|手把手教你写网络爬虫（5）：Pha...|<div id=\"cnblogs_...|python,手把手教你写网络爬虫...|\n",
      "|     12247|        18|      python|用 Plumbum 开发 Pyth...|<div id=\"article_...|python,用 Plumbum ...|\n",
      "|     12249|        18|      python|手把手教你写网络爬虫（6）：分布式...|<div id=\"cnblogs_...|python,手把手教你写网络爬虫...|\n",
      "|     12251|        18|      python|手把手教你写网络爬虫（7）：URL...|<p><a href=\"http:...|python,手把手教你写网络爬虫...|\n",
      "|     12252|        18|      python|手把手教你写网络爬虫（8）：彻底解...|<div id=\"cnblogs_...|python,手把手教你写网络爬虫...|\n",
      "|     12253|        18|      python|      爬取豆瓣短评之《后来的我们》|<p>《后来的我们》上映了，或许大...|python,爬取豆瓣短评之《后来...|\n",
      "|     12254|        18|      python|5 个用 Python 编写 we...|<p><a href=\"http:...|python,5 个用 Pytho...|\n",
      "|     12255|        18|      python|使用交互式 shell 来增强你的...|<p>Python 编程语言已经成...|python,使用交互式 shel...|\n",
      "|     12256|        18|      python|      Python 项目可以有多大|<div><p>总是看到有人说，动...|python,Python 项目可...|\n",
      "|     12257|        18|      python|   6 个 Python 的日期时间库|<p>曾几何时，我们中的一个人（L...|python,6 个 Python...|\n",
      "|     12258|        18|      python|3 个 Python 模板库比较 ...|<div id=\"article_...|python,3 个 Python...|\n",
      "|     12259|        18|      python|用 Python 实现模拟登录正方...|<div id=\"post-con...|python,用 Python 实...|\n",
      "|     12260|        18|      python|爬虫进阶：反反爬虫技巧 高级网络爬...|<blockquote><p>主要...|python,爬虫进阶：反反爬虫技...|\n",
      "|     12261|        18|      python|用 Python 分析了 20 万...|<p>首先，神枪镇楼</p><p>...|python,用 Python 分...|\n",
      "|     12262|        18|      python|Python 字节码介绍 Pyth...|<div id=\"article_...|python,Python 字节码...|\n",
      "|     12263|        18|      python|为什么 Python 开发人员应该...|<blockquote><p>只用...|python,为什么 Python...|\n",
      "|     12264|        18|      python|    日常 Python 编程优雅之道|<blockquote><p>3 ...|python,日常 Python ...|\n",
      "+----------+----------+------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 读取文章，进行每篇张分词\n",
    "oa.spark.sql(\"use article\")\n",
    "# article_data = oa.spark.sql(\"select * from article_data limit 10\")\n",
    "article_data = oa.spark.sql(\"select * from article_data where channel_id = 18 limit 10\")\n",
    "article_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文章数据进行分词处理,得到分词结果\n",
    "# 分词\n",
    "def segmentation(partition):\n",
    "    import os\n",
    "    import re\n",
    "\n",
    "    import jieba\n",
    "    import jieba.analyse\n",
    "    import jieba.posseg as pseg\n",
    "    import codecs\n",
    "\n",
    "    abspath = \"/root/words\"\n",
    "\n",
    "    # 结巴加载用户词典\n",
    "    userDict_path = os.path.join(abspath, \"ITKeywords.txt\")\n",
    "    jieba.load_userdict(userDict_path)\n",
    "\n",
    "    # 停用词文本\n",
    "    stopwords_path = os.path.join(abspath, \"stopwords.txt\")\n",
    "\n",
    "    def get_stopwords_list():\n",
    "        \"\"\"返回stopwords列表\"\"\"\n",
    "        stopwords_list = [i.strip()\n",
    "                          for i in codecs.open(stopwords_path).readlines()]\n",
    "        return stopwords_list\n",
    "\n",
    "    # 所有的停用词列表\n",
    "    stopwords_list = get_stopwords_list()\n",
    "\n",
    "    # 分词\n",
    "    def cut_sentence(sentence):\n",
    "        \"\"\"对切割之后的词语进行过滤，去除停用词，保留名词，英文和自定义词库中的词，长度大于2的词\"\"\"\n",
    "        # print(sentence,\"*\"*100)\n",
    "        # eg:[pair('今天', 't'), pair('有', 'd'), pair('雾', 'n'), pair('霾', 'g')]\n",
    "        seg_list = pseg.lcut(sentence)\n",
    "        seg_list = [i for i in seg_list if i.flag not in stopwords_list]\n",
    "        filtered_words_list = []\n",
    "        for seg in seg_list:\n",
    "            # print(seg)\n",
    "            if len(seg.word) <= 1:\n",
    "                continue\n",
    "            elif seg.flag == \"eng\":\n",
    "                if len(seg.word) <= 2:\n",
    "                    continue\n",
    "                else:\n",
    "                    filtered_words_list.append(seg.word)\n",
    "            elif seg.flag.startswith(\"n\"):\n",
    "                filtered_words_list.append(seg.word)\n",
    "            elif seg.flag in [\"x\", \"eng\"]:  # 是自定一个词语或者是英文单词\n",
    "                filtered_words_list.append(seg.word)\n",
    "        return filtered_words_list\n",
    "\n",
    "    for row in partition:\n",
    "        sentence = re.sub(\"<.*?>\", \"\", row.sentence)    # 替换掉标签数据\n",
    "        words = cut_sentence(sentence)\n",
    "        yield row.article_id, row.channel_id, words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = article_data.rdd.mapPartitions(segmentation).toDF(['article_id', 'channel_id', 'words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n",
      "|article_id|channel_id|               words|\n",
      "+----------+----------+--------------------+\n",
      "|     12237|        18|[python, 区块链, Pyt...|\n",
      "|     12238|        18|[python, Python, ...|\n",
      "|     12243|        18|[python, 手把手, 网络,...|\n",
      "|     12245|        18|[python, 手把手, 网络,...|\n",
      "|     12247|        18|[python, Plumbum,...|\n",
      "|     12249|        18|[python, 手把手, 网络,...|\n",
      "|     12251|        18|[python, 手把手, 网络,...|\n",
      "|     12252|        18|[python, 手把手, 网络,...|\n",
      "|     12253|        18|[python, 豆瓣, 大家, ...|\n",
      "|     12254|        18|[python, Python, ...|\n",
      "|     12255|        18|[python, shell, P...|\n",
      "|     12256|        18|[python, Python, ...|\n",
      "|     12257|        18|[python, Python, ...|\n",
      "|     12258|        18|[python, Python, ...|\n",
      "|     12259|        18|[python, Python, ...|\n",
      "|     12260|        18|[python, 爬虫, 进阶, ...|\n",
      "|     12261|        18|[python, Python, ...|\n",
      "|     12262|        18|[python, Python, ...|\n",
      "|     12263|        18|[python, Python, ...|\n",
      "|     12264|        18|[python, Python, ...|\n",
      "+----------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 得到词频CV模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先计算分词之后的每篇文章的词频，得到CV模型\n",
    "# 统计所有文章不同的词，组成一个词列表 words_list = [1,2,3,,34,4,45,56,67,78,8.......,,,,.]\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "cv = CountVectorizer(inputCol='words', outputCol='countFeatures', vocabSize=2000, minDF=1.0)\n",
    "cv_model = cv.fit(words_df)\n",
    "\n",
    "# 然后根据词频计算IDF以及词，得到IDF模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model.write().overwrite().save(\"hdfs://hadoop-master:9000/headlines/models/test.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizerModel\n",
    "cv_m = CountVectorizerModel.load(\"hdfs://hadoop-master:9000/headlines/models/test.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result = cv_m.transform(words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------------------+\n",
      "|article_id|channel_id|               words|       countFeatures|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "|     12237|        18|[python, 区块链, Pyt...|(2000,[0,1,2,3,4,...|\n",
      "|     12238|        18|[python, Python, ...|(2000,[0,1,4,5,7,...|\n",
      "|     12243|        18|[python, 手把手, 网络,...|(2000,[0,2,3,4,5,...|\n",
      "|     12245|        18|[python, 手把手, 网络,...|(2000,[0,1,3,5,6,...|\n",
      "|     12247|        18|[python, Plumbum,...|(2000,[0,1,2,3,4,...|\n",
      "|     12249|        18|[python, 手把手, 网络,...|(2000,[0,3,9,11,1...|\n",
      "|     12251|        18|[python, 手把手, 网络,...|(2000,[0,5,9,10,1...|\n",
      "|     12252|        18|[python, 手把手, 网络,...|(2000,[0,3,5,9,12...|\n",
      "|     12253|        18|[python, 豆瓣, 大家, ...|(2000,[0,1,2,3,6,...|\n",
      "|     12254|        18|[python, Python, ...|(2000,[0,1,3,5,8,...|\n",
      "|     12255|        18|[python, shell, P...|(2000,[0,3,5,7,9,...|\n",
      "|     12256|        18|[python, Python, ...|(2000,[0,5,7,9,20...|\n",
      "|     12257|        18|[python, Python, ...|(2000,[0,3,5,7,8,...|\n",
      "|     12258|        18|[python, Python, ...|(2000,[0,1,5,7,9,...|\n",
      "|     12259|        18|[python, Python, ...|(2000,[0,1,2,3,4,...|\n",
      "|     12260|        18|[python, 爬虫, 进阶, ...|(2000,[0,2,3,4,5,...|\n",
      "|     12261|        18|[python, Python, ...|(2000,[0,1,2,3,4,...|\n",
      "|     12262|        18|[python, Python, ...|(2000,[0,1,2,5,7,...|\n",
      "|     12263|        18|[python, Python, ...|(2000,[0,5,9,12,2...|\n",
      "|     12264|        18|[python, Python, ...|(2000,[0,1,2,3,4,...|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 得到IDF模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDF 模型\n",
    "from pyspark.ml.feature import IDF\n",
    "idf = IDF(inputCol=\"countFeatures\", outputCol=\"idfFeatures\")\n",
    "idfModel = idf.fit(cv_result)\n",
    "idfModel.write().overwrite().save(\"hdfs://hadoop-master:9000/headlines/models/testIDF.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['&#',\n",
       " 'print',\n",
       " '__',\n",
       " 'pa',\n",
       " 'self',\n",
       " 'Python',\n",
       " 'name',\n",
       " '代码',\n",
       " 'def',\n",
       " 'python',\n",
       " '函数',\n",
       " 'ul',\n",
       " '方法',\n",
       " '数据',\n",
       " 'import',\n",
       " '对象',\n",
       " 'for',\n",
       " 'return',\n",
       " '.a',\n",
       " '参数',\n",
       " '文件',\n",
       " 'class',\n",
       " '结果',\n",
       " 'data',\n",
       " 'list',\n",
       " '列表',\n",
       " 'get',\n",
       " '字符串',\n",
       " 'com',\n",
       " 'True',\n",
       " '模块',\n",
       " 'from',\n",
       " 'url',\n",
       " '问题',\n",
       " '元素',\n",
       " '内容',\n",
       " 'str',\n",
       " 'time',\n",
       " 'the',\n",
       " '时候',\n",
       " '信息',\n",
       " '定义',\n",
       " 'None',\n",
       " 'res',\n",
       " 'key',\n",
       " '类型',\n",
       " '方式',\n",
       " '属性',\n",
       " 'request',\n",
       " '.h',\n",
       " 'value',\n",
       " '程序',\n",
       " '字典',\n",
       " 'test',\n",
       " '用户',\n",
       " 'range',\n",
       " 'https',\n",
       " 'else',\n",
       " 'type',\n",
       " 'input',\n",
       " '模型',\n",
       " 'init',\n",
       " 'user',\n",
       " 'False',\n",
       " 'index',\n",
       " 'set',\n",
       " 'dict',\n",
       " 'age',\n",
       " 'http',\n",
       " 'text',\n",
       " 'int',\n",
       " 'and',\n",
       " 'num',\n",
       " '功能',\n",
       " 'amp',\n",
       " '时间',\n",
       " 'file',\n",
       " 'main',\n",
       " 'len',\n",
       " 'utf',\n",
       " '项目',\n",
       " 'count',\n",
       " 'start',\n",
       " 'func',\n",
       " '情况',\n",
       " 'args',\n",
       " '字符',\n",
       " '线程',\n",
       " '进程',\n",
       " 'object',\n",
       " 'json',\n",
       " 'not',\n",
       " '实例',\n",
       " 'with',\n",
       " 'item',\n",
       " 'open',\n",
       " 'www',\n",
       " '目录',\n",
       " '数字',\n",
       " 'format',\n",
       " 'content',\n",
       " 'new',\n",
       " 'app',\n",
       " '爬虫',\n",
       " 'info',\n",
       " 'django',\n",
       " 'response',\n",
       " 'plt',\n",
       " '命令',\n",
       " 'ppend',\n",
       " 'title',\n",
       " '索引',\n",
       " '过程',\n",
       " '版本',\n",
       " 'while',\n",
       " '语句',\n",
       " '语言',\n",
       " 'html',\n",
       " 'line',\n",
       " 'run',\n",
       " '装饰',\n",
       " '页面',\n",
       " '图片',\n",
       " '部分',\n",
       " 'obj',\n",
       " 'size',\n",
       " '数据库',\n",
       " 'install',\n",
       " '格式',\n",
       " '文章',\n",
       " '服务器',\n",
       " '系统',\n",
       " '元组',\n",
       " 'Django',\n",
       " '字段',\n",
       " '例子',\n",
       " 'via',\n",
       " '算法',\n",
       " 'max',\n",
       " 'pip',\n",
       " '错误',\n",
       " 'socket',\n",
       " 'tml',\n",
       " 'models',\n",
       " '编码',\n",
       " 'hello',\n",
       " '文档',\n",
       " 'div',\n",
       " '路径',\n",
       " 'string',\n",
       " '任务',\n",
       " '地址',\n",
       " 'next',\n",
       " 'random',\n",
       " 'end',\n",
       " 'join',\n",
       " 'root',\n",
       " 'read',\n",
       " 'kwargs',\n",
       " '节点',\n",
       " 'close',\n",
       " 'txt',\n",
       " 'find',\n",
       " 'model',\n",
       " '链接',\n",
       " 'train',\n",
       " 'bin',\n",
       " 'msg',\n",
       " '名字',\n",
       " '名称',\n",
       " 'image',\n",
       " '序列',\n",
       " 'sys',\n",
       " '数组',\n",
       " '特征',\n",
       " 'python3',\n",
       " 'color',\n",
       " 'mod',\n",
       " 'all',\n",
       " '内存',\n",
       " '大家',\n",
       " '形式',\n",
       " '机器学习',\n",
       " 'defa',\n",
       " '网站',\n",
       " '记录',\n",
       " '环境',\n",
       " 'try',\n",
       " 'requests',\n",
       " 'except',\n",
       " '客户端',\n",
       " 'usr',\n",
       " '浏览器',\n",
       " '利用',\n",
       " '模式',\n",
       " '关键字',\n",
       " '条件',\n",
       " 'log',\n",
       " 'URL',\n",
       " 'write',\n",
       " '赋值',\n",
       " 'form',\n",
       " 'code',\n",
       " '工具',\n",
       " '标签',\n",
       " '数据类型',\n",
       " 'session',\n",
       " '基础',\n",
       " 'img',\n",
       " 'add',\n",
       " 'encoding',\n",
       " 'Android',\n",
       " 'dic',\n",
       " 'group',\n",
       " '整数',\n",
       " '网络',\n",
       " 'score',\n",
       " '基本',\n",
       " 'values',\n",
       " 'github',\n",
       " 'sum',\n",
       " '长度',\n",
       " 'function',\n",
       " 'yield',\n",
       " 'split',\n",
       " 'send',\n",
       " '框架',\n",
       " 'ssword',\n",
       " 'server',\n",
       " 'filter',\n",
       " '状态',\n",
       " 'org',\n",
       " 'elif',\n",
       " '关系',\n",
       " '文本',\n",
       " 'sleep',\n",
       " '语法',\n",
       " 'show',\n",
       " '数量',\n",
       " '数据集',\n",
       " '解释器',\n",
       " 'lambda',\n",
       " '表达式',\n",
       " 'label',\n",
       " '返回值',\n",
       " 'API',\n",
       " '网页',\n",
       " 'config',\n",
       " 'target',\n",
       " '脚本',\n",
       " '顺序',\n",
       " '密码',\n",
       " 'width',\n",
       " 'login',\n",
       " 'update',\n",
       " 'coding',\n",
       " '示例',\n",
       " '代表',\n",
       " 'username',\n",
       " 'error',\n",
       " '教程',\n",
       " 'logging',\n",
       " 'last',\n",
       " '无法',\n",
       " '迭代器',\n",
       " '图像',\n",
       " 'message',\n",
       " '视图',\n",
       " 'length',\n",
       " '字节',\n",
       " 'client',\n",
       " 'number',\n",
       " '文件夹',\n",
       " 'ret',\n",
       " 'datetime',\n",
       " 'Flask',\n",
       " 'numpy',\n",
       " '分类',\n",
       " '产生',\n",
       " '模板',\n",
       " '消息',\n",
       " '东西',\n",
       " '技术',\n",
       " '队列',\n",
       " 'array',\n",
       " 'date',\n",
       " '资源',\n",
       " 'table',\n",
       " 'body',\n",
       " 'left',\n",
       " '编程',\n",
       " 'post',\n",
       " 'scrapy',\n",
       " 'break',\n",
       " 'threading',\n",
       " '效果',\n",
       " 'block',\n",
       " 'shape',\n",
       " 'tuple',\n",
       " '日志',\n",
       " 'create',\n",
       " '排序',\n",
       " 'flask',\n",
       " 'search',\n",
       " 'conn',\n",
       " 'one',\n",
       " 'call',\n",
       " 'objects',\n",
       " 'items',\n",
       " '全部',\n",
       " 'headers',\n",
       " 'min',\n",
       " 'cls',\n",
       " 'first',\n",
       " 'row',\n",
       " 'env',\n",
       " '逻辑',\n",
       " 'select',\n",
       " '总结',\n",
       " 'map',\n",
       " 'names',\n",
       " 'sql',\n",
       " 'cv2',\n",
       " 'HTTP',\n",
       " '区别',\n",
       " 'cookie',\n",
       " '实际',\n",
       " 'float',\n",
       " '切片',\n",
       " 'var',\n",
       " 'rse',\n",
       " 'settings',\n",
       " 'filename',\n",
       " 'ram',\n",
       " 'urls',\n",
       " 'User',\n",
       " '结构',\n",
       " '建议',\n",
       " 'method',\n",
       " 'csv',\n",
       " '声明',\n",
       " 'port',\n",
       " '矩阵',\n",
       " 'pop',\n",
       " '入门',\n",
       " '概念',\n",
       " 'Thread',\n",
       " 'bytes',\n",
       " 'this',\n",
       " 'output',\n",
       " 'hash',\n",
       " '目标',\n",
       " 'view',\n",
       " 'web',\n",
       " '范围',\n",
       " 'foo',\n",
       " 'local',\n",
       " 'iter',\n",
       " 'word',\n",
       " 'r2',\n",
       " '原因',\n",
       " 'right',\n",
       " '##',\n",
       " '内置',\n",
       " 'del',\n",
       " 'abc',\n",
       " 'Hello',\n",
       " '官方',\n",
       " 'price',\n",
       " '协程',\n",
       " 'href',\n",
       " 'dir',\n",
       " 'File',\n",
       " 'lst',\n",
       " 'Windows',\n",
       " 'admin',\n",
       " '速度',\n",
       " 'task',\n",
       " '课程',\n",
       " '协议',\n",
       " 'logger',\n",
       " 'current',\n",
       " 'queue',\n",
       " '计算机',\n",
       " 'encode',\n",
       " 'ndas',\n",
       " '地方',\n",
       " 'redis',\n",
       " 'Python3',\n",
       " 'base',\n",
       " '代理',\n",
       " '空格',\n",
       " 'font',\n",
       " 'keys',\n",
       " '作者',\n",
       " 'process',\n",
       " '次数',\n",
       " 'views',\n",
       " 'decode',\n",
       " 'The',\n",
       " 'matplotlib',\n",
       " '公司',\n",
       " '源码',\n",
       " '父类',\n",
       " '平台',\n",
       " 'Person',\n",
       " 'plot',\n",
       " '主题',\n",
       " 'node',\n",
       " '数值',\n",
       " 'iPhone',\n",
       " 'strip',\n",
       " 'element',\n",
       " 'temp',\n",
       " '标准',\n",
       " '子类',\n",
       " 'world',\n",
       " '字母',\n",
       " '视频',\n",
       " 'height',\n",
       " '步骤',\n",
       " 'status',\n",
       " '虚拟环境',\n",
       " 'lib',\n",
       " '中文',\n",
       " 'sess',\n",
       " 'mysql',\n",
       " '策略',\n",
       " '用法',\n",
       " '规则',\n",
       " 'sort',\n",
       " 'render',\n",
       " 'total',\n",
       " 'POST',\n",
       " 'api',\n",
       " 'you',\n",
       " 'val',\n",
       " 'token',\n",
       " 'raise',\n",
       " 'urllib',\n",
       " 'doc',\n",
       " 'global',\n",
       " '指向',\n",
       " 'loop',\n",
       " 'GET',\n",
       " 'match',\n",
       " 'replace',\n",
       " '全局',\n",
       " 'soup',\n",
       " '大量',\n",
       " '个数',\n",
       " '二进制',\n",
       " 'load',\n",
       " 'host',\n",
       " 'dtype',\n",
       " '样本',\n",
       " 'save',\n",
       " '普通',\n",
       " 'true',\n",
       " '用户名',\n",
       " '子进程',\n",
       " 'View',\n",
       " 'copy',\n",
       " 'cmd',\n",
       " 'findall',\n",
       " '命名',\n",
       " 'CPU',\n",
       " 'bar',\n",
       " 'remove',\n",
       " 'tag',\n",
       " 'event',\n",
       " 'before',\n",
       " 'thread',\n",
       " 'HTML',\n",
       " 'python2',\n",
       " 'Out',\n",
       " 'blog',\n",
       " '深度学习',\n",
       " 'driver',\n",
       " '评论',\n",
       " 'jpg',\n",
       " '效率',\n",
       " '维度',\n",
       " 'make',\n",
       " 'isinstance',\n",
       " 'DataFrame',\n",
       " '性能',\n",
       " '作用域',\n",
       " 'static',\n",
       " 'unicode',\n",
       " 'head',\n",
       " 'header',\n",
       " 'Java',\n",
       " 'zip',\n",
       " '空间',\n",
       " 'Process',\n",
       " 'script',\n",
       " 'sex',\n",
       " '运算符',\n",
       " 'site',\n",
       " '感觉',\n",
       " 'now',\n",
       " 'example',\n",
       " 'template',\n",
       " '特性',\n",
       " '人工智能',\n",
       " 'src',\n",
       " '符号',\n",
       " '博客',\n",
       " 'out',\n",
       " 'png',\n",
       " 'rams',\n",
       " '神经网络',\n",
       " 'cursor',\n",
       " 'recv',\n",
       " 'super',\n",
       " 'Foo',\n",
       " '程序员',\n",
       " '嵌套',\n",
       " 'insert',\n",
       " '事情',\n",
       " '绘制',\n",
       " 'UTF',\n",
       " 'like',\n",
       " 'check',\n",
       " '能力',\n",
       " '实例化',\n",
       " 'Code',\n",
       " '电影',\n",
       " '概率',\n",
       " 'mode',\n",
       " '领域',\n",
       " 'Beautif',\n",
       " 'job',\n",
       " 'ckages',\n",
       " 'query',\n",
       " '机制',\n",
       " '数据结构',\n",
       " '有所',\n",
       " '选项',\n",
       " 'xxx',\n",
       " 'sub',\n",
       " 'Redis',\n",
       " '编程语言',\n",
       " 'field',\n",
       " 'asyncio',\n",
       " 'route',\n",
       " 'top',\n",
       " '全局变量',\n",
       " '动态',\n",
       " 'year',\n",
       " '新建',\n",
       " 'source',\n",
       " 'handler',\n",
       " 'context',\n",
       " 'mean',\n",
       " '软件',\n",
       " 'net',\n",
       " 'register',\n",
       " '端口',\n",
       " '应用程序',\n",
       " '目的',\n",
       " 'home',\n",
       " '单词',\n",
       " 'bool',\n",
       " 'that',\n",
       " 'where',\n",
       " 'contrib',\n",
       " 'command',\n",
       " 'localhost',\n",
       " 'instance',\n",
       " '闭包',\n",
       " '一个对象',\n",
       " 'version',\n",
       " 'list1',\n",
       " '括号',\n",
       " 'continue',\n",
       " '游戏',\n",
       " '序列化',\n",
       " '容器',\n",
       " 'connect',\n",
       " '权限',\n",
       " 'order',\n",
       " 'conf',\n",
       " 'exit',\n",
       " 'col',\n",
       " '事件',\n",
       " '向量',\n",
       " 'are',\n",
       " 'Linux',\n",
       " 'box',\n",
       " 'for循环',\n",
       " 'email',\n",
       " 'state',\n",
       " 'student',\n",
       " 'inner',\n",
       " 'lock',\n",
       " '核心',\n",
       " '命令行',\n",
       " '终端',\n",
       " 'city',\n",
       " '意思',\n",
       " 'tiprocessing',\n",
       " '个人',\n",
       " '按钮',\n",
       " 'most',\n",
       " 'book',\n",
       " 'JSON',\n",
       " 'C++',\n",
       " '配置文件',\n",
       " 'alex',\n",
       " 'sudo',\n",
       " '部署',\n",
       " 'selenium',\n",
       " 'step',\n",
       " 'address',\n",
       " '机器',\n",
       " '验证码',\n",
       " '商品',\n",
       " 'reverse',\n",
       " '交易',\n",
       " 'flag',\n",
       " '方向',\n",
       " 'debug',\n",
       " '电脑',\n",
       " 'delete',\n",
       " 'TensorFlow',\n",
       " 'V2EX',\n",
       " 'baidu',\n",
       " 'Exception',\n",
       " '原理',\n",
       " '加密',\n",
       " 'level',\n",
       " 'rray',\n",
       " 'Unicode',\n",
       " 'tmp',\n",
       " 'Soup',\n",
       " '可视化',\n",
       " '标记',\n",
       " '服务端',\n",
       " 'Chrome',\n",
       " 'has',\n",
       " 'help',\n",
       " '大写',\n",
       " 'child',\n",
       " '有点',\n",
       " 'choice',\n",
       " 'sorted',\n",
       " '类别',\n",
       " 'article',\n",
       " 'nginx',\n",
       " '格式化',\n",
       " '文件名',\n",
       " 'dataset',\n",
       " 'manage',\n",
       " '意义',\n",
       " '公众号',\n",
       " 'Queue',\n",
       " '关联',\n",
       " '文字',\n",
       " '成员',\n",
       " 'wrapper',\n",
       " '级别',\n",
       " '流程',\n",
       " '路由',\n",
       " 'axis',\n",
       " '手动',\n",
       " '案例',\n",
       " 'put',\n",
       " 'labels',\n",
       " 'style',\n",
       " '年龄',\n",
       " '场景',\n",
       " 'Model',\n",
       " '方面',\n",
       " 'execute',\n",
       " 'cache',\n",
       " 'tensorflow',\n",
       " '思路',\n",
       " 'fields',\n",
       " 'build',\n",
       " 'author',\n",
       " '颜色',\n",
       " 'your',\n",
       " '学生',\n",
       " '中间件',\n",
       " 'other',\n",
       " '环境变量',\n",
       " 'use',\n",
       " 'pool',\n",
       " 'files',\n",
       " 'border',\n",
       " 'words',\n",
       " '小时',\n",
       " '自带',\n",
       " 'async',\n",
       " 'collections',\n",
       " 'recent',\n",
       " 'shell',\n",
       " 'wait',\n",
       " '距离',\n",
       " 'css',\n",
       " 'arg',\n",
       " 'Session',\n",
       " 'math',\n",
       " 'Student',\n",
       " 'Tensor',\n",
       " 'sklearn',\n",
       " '表单',\n",
       " 'dumps',\n",
       " 'margin',\n",
       " 'button',\n",
       " 'xml',\n",
       " 'users',\n",
       " 'getattr',\n",
       " 'cur',\n",
       " '标题',\n",
       " '界面',\n",
       " 'timeout',\n",
       " 'browser',\n",
       " 'course',\n",
       " 'git',\n",
       " '方案',\n",
       " '数学',\n",
       " 'repr',\n",
       " 'Scrapy',\n",
       " 'learning',\n",
       " 'Users',\n",
       " 'background',\n",
       " '办法',\n",
       " 'etc',\n",
       " '社区',\n",
       " '组件',\n",
       " '答案',\n",
       " 'link',\n",
       " 'Name',\n",
       " 'reduce',\n",
       " 'two',\n",
       " 'btn',\n",
       " 'application',\n",
       " '源代码',\n",
       " '2d',\n",
       " 'Web',\n",
       " 'This',\n",
       " 'win',\n",
       " 'rser',\n",
       " 'iterable',\n",
       " 'rent',\n",
       " 'real',\n",
       " 'column',\n",
       " 'Ctrl',\n",
       " 'pwd',\n",
       " '键值对',\n",
       " 'ttern',\n",
       " '结尾',\n",
       " 'property',\n",
       " '资料',\n",
       " '代码块',\n",
       " '浮点数',\n",
       " '世界',\n",
       " '信号',\n",
       " '数据科学',\n",
       " 'fit',\n",
       " 'CharField',\n",
       " 'java',\n",
       " 'spider',\n",
       " 'display',\n",
       " 'demo',\n",
       " '套接字',\n",
       " 'INFO',\n",
       " 'frame',\n",
       " 'test1',\n",
       " 'Request',\n",
       " 'loc',\n",
       " 'GIL',\n",
       " 'release',\n",
       " '区分',\n",
       " 'batch',\n",
       " 'stop',\n",
       " 'movie',\n",
       " 'compile',\n",
       " 'connection',\n",
       " 'subprocess',\n",
       " 'nums',\n",
       " 'utf8',\n",
       " '英文',\n",
       " 'HttpResponse',\n",
       " 'ckage',\n",
       " '百度',\n",
       " '网址',\n",
       " '特点',\n",
       " 'clear',\n",
       " 'weight',\n",
       " 'predict',\n",
       " '本质',\n",
       " 'tree',\n",
       " 'addr',\n",
       " 'dding',\n",
       " 'action',\n",
       " '单位',\n",
       " 'stdout',\n",
       " '笔记',\n",
       " 'images',\n",
       " '产品',\n",
       " 'columns',\n",
       " '原文',\n",
       " 'pickle',\n",
       " 'exe',\n",
       " 'arr',\n",
       " '编辑',\n",
       " 'struct',\n",
       " 'seq',\n",
       " 'master',\n",
       " '知乎',\n",
       " 'loads',\n",
       " 'false',\n",
       " '开源',\n",
       " 'conda',\n",
       " '官网',\n",
       " 'DEBUG',\n",
       " '缺点',\n",
       " '解决方案',\n",
       " 'options',\n",
       " 'position',\n",
       " 'lower',\n",
       " 'signature',\n",
       " 'pre',\n",
       " 'fun',\n",
       " 'pyplot',\n",
       " '区域',\n",
       " 'rate',\n",
       " 'windows',\n",
       " 'tornado',\n",
       " 'loss',\n",
       " '权重',\n",
       " 'callback',\n",
       " 'webdriver',\n",
       " 'auth',\n",
       " '账号',\n",
       " '优点',\n",
       " '经验',\n",
       " '指令',\n",
       " 'gender',\n",
       " 'TCP',\n",
       " 'World',\n",
       " '篇文章',\n",
       " '多进程',\n",
       " 'can',\n",
       " 'chain',\n",
       " '类名',\n",
       " '后台',\n",
       " 'randint',\n",
       " 'pycharm',\n",
       " 'offset',\n",
       " '关键',\n",
       " 'person',\n",
       " '插件',\n",
       " 'download',\n",
       " 'framework',\n",
       " '定位',\n",
       " 'Mozilla',\n",
       " 'money',\n",
       " 'comment',\n",
       " 'Traceback',\n",
       " '命名空间',\n",
       " 'generator',\n",
       " '业务',\n",
       " 'uwsgi',\n",
       " 'eval',\n",
       " 'day',\n",
       " 'sns',\n",
       " 'Age',\n",
       " '解码',\n",
       " 'matrix',\n",
       " 'old',\n",
       " 'cookies',\n",
       " 'dev',\n",
       " 'docker',\n",
       " '谢谢',\n",
       " '末尾',\n",
       " 'redirect',\n",
       " 'account',\n",
       " '分支',\n",
       " '哈希',\n",
       " 'Python2',\n",
       " 'func1',\n",
       " '价格',\n",
       " 'include',\n",
       " 'proxy',\n",
       " 'TypeError',\n",
       " 'enumerate',\n",
       " 'only',\n",
       " 'ASCII',\n",
       " '形参',\n",
       " 'product',\n",
       " '同学',\n",
       " '调度',\n",
       " 'window',\n",
       " '局部',\n",
       " 'Column',\n",
       " '读者',\n",
       " 'meta',\n",
       " '逗号',\n",
       " 'docs',\n",
       " 'case',\n",
       " 'empty',\n",
       " 'Return',\n",
       " '缺失值',\n",
       " 'center',\n",
       " '区块链',\n",
       " 'bottom',\n",
       " 'nodes',\n",
       " 'JavaScript',\n",
       " 'bind',\n",
       " '阶段',\n",
       " 'finally',\n",
       " 'Agent',\n",
       " '程度',\n",
       " 'Book',\n",
       " '消费者',\n",
       " '开发者',\n",
       " 'Anaconda',\n",
       " 'charset',\n",
       " 'each',\n",
       " 'pid',\n",
       " '细节',\n",
       " 'none',\n",
       " 'raw',\n",
       " '中国',\n",
       " 'country',\n",
       " 'detail',\n",
       " 'amount',\n",
       " 'stack',\n",
       " 'salary',\n",
       " 'layer',\n",
       " '技能',\n",
       " 'feature',\n",
       " 'upper',\n",
       " '交流',\n",
       " 'gevent',\n",
       " 'NAME',\n",
       " '手机',\n",
       " 'linux',\n",
       " 'Pandas',\n",
       " 'learn',\n",
       " 'sheet',\n",
       " '梯度',\n",
       " '标准库',\n",
       " 'gbk',\n",
       " '客户',\n",
       " 'float32',\n",
       " '朋友',\n",
       " 'pos',\n",
       " '张量',\n",
       " 'grid',\n",
       " 'NaN',\n",
       " 'simple',\n",
       " 'List',\n",
       " 'common',\n",
       " 'project',\n",
       " '明白',\n",
       " '打开文件',\n",
       " '表格',\n",
       " 'String',\n",
       " 'await',\n",
       " 'Jupyter',\n",
       " 'red',\n",
       " 'argument',\n",
       " '姓名',\n",
       " 'using',\n",
       " 'GitHub',\n",
       " 'Google',\n",
       " 'will',\n",
       " '微信公众号',\n",
       " '评分',\n",
       " '规范',\n",
       " '内置函数',\n",
       " 'req',\n",
       " 'tcp',\n",
       " '书籍',\n",
       " 'bit',\n",
       " 'auto',\n",
       " '过滤器',\n",
       " '邮箱',\n",
       " '风格',\n",
       " 'Type',\n",
       " '重点',\n",
       " '控件',\n",
       " '调用函数',\n",
       " '底层',\n",
       " '实参',\n",
       " 'extend',\n",
       " '小写',\n",
       " 'after',\n",
       " '默认参数',\n",
       " 'Field',\n",
       " 'work',\n",
       " 'initHighlightingOnLoad',\n",
       " 'hljs',\n",
       " 'h2',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以进行转换\n",
    "cv_m.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.29385141, 0.66970014, 1.17276627, 0.61771575, 1.53059209,\n",
       "       0.49503521, 0.91052588, 0.62439357, 0.88146756, 0.        ,\n",
       "       0.91251001, 0.83376675, 0.70376959, 0.90731005, 0.75566754,\n",
       "       1.13267884, 0.82145188, 1.06220192, 0.91624089, 1.0354578 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfModel.idf.toArray()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.依据CV及IDF得到TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDF对CV结果进行计算TFIDF\n",
    "from pyspark.ml.feature import IDFModel\n",
    "idf_model = IDFModel.load(\"hdfs://hadoop-master:9000/headlines/models/testIDF.model\")\n",
    "tfidf_res = idf_model.transform(cv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------------------+--------------------+\n",
      "|article_id|channel_id|               words|       countFeatures|         idfFeatures|\n",
      "+----------+----------+--------------------+--------------------+--------------------+\n",
      "|     12237|        18|[python, 区块链, Pyt...|(2000,[0,1,2,3,4,...|(2000,[0,1,2,3,4,...|\n",
      "|     12238|        18|[python, Python, ...|(2000,[0,1,4,5,7,...|(2000,[0,1,4,5,7,...|\n",
      "|     12243|        18|[python, 手把手, 网络,...|(2000,[0,2,3,4,5,...|(2000,[0,2,3,4,5,...|\n",
      "|     12245|        18|[python, 手把手, 网络,...|(2000,[0,1,3,5,6,...|(2000,[0,1,3,5,6,...|\n",
      "|     12247|        18|[python, Plumbum,...|(2000,[0,1,2,3,4,...|(2000,[0,1,2,3,4,...|\n",
      "|     12249|        18|[python, 手把手, 网络,...|(2000,[0,3,9,11,1...|(2000,[0,3,9,11,1...|\n",
      "|     12251|        18|[python, 手把手, 网络,...|(2000,[0,5,9,10,1...|(2000,[0,5,9,10,1...|\n",
      "|     12252|        18|[python, 手把手, 网络,...|(2000,[0,3,5,9,12...|(2000,[0,3,5,9,12...|\n",
      "|     12253|        18|[python, 豆瓣, 大家, ...|(2000,[0,1,2,3,6,...|(2000,[0,1,2,3,6,...|\n",
      "|     12254|        18|[python, Python, ...|(2000,[0,1,3,5,8,...|(2000,[0,1,3,5,8,...|\n",
      "|     12255|        18|[python, shell, P...|(2000,[0,3,5,7,9,...|(2000,[0,3,5,7,9,...|\n",
      "|     12256|        18|[python, Python, ...|(2000,[0,5,7,9,20...|(2000,[0,5,7,9,20...|\n",
      "|     12257|        18|[python, Python, ...|(2000,[0,3,5,7,8,...|(2000,[0,3,5,7,8,...|\n",
      "|     12258|        18|[python, Python, ...|(2000,[0,1,5,7,9,...|(2000,[0,1,5,7,9,...|\n",
      "|     12259|        18|[python, Python, ...|(2000,[0,1,2,3,4,...|(2000,[0,1,2,3,4,...|\n",
      "|     12260|        18|[python, 爬虫, 进阶, ...|(2000,[0,2,3,4,5,...|(2000,[0,2,3,4,5,...|\n",
      "|     12261|        18|[python, Python, ...|(2000,[0,1,2,3,4,...|(2000,[0,1,2,3,4,...|\n",
      "|     12262|        18|[python, Python, ...|(2000,[0,1,2,5,7,...|(2000,[0,1,2,5,7,...|\n",
      "|     12263|        18|[python, Python, ...|(2000,[0,5,9,12,2...|(2000,[0,5,9,12,2...|\n",
      "|     12264|        18|[python, Python, ...|(2000,[0,1,2,3,4,...|(2000,[0,1,2,3,4,...|\n",
      "+----------+----------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1265词的 {索引 以及 权重}\n",
    "def func(partition):\n",
    "    TOPK = 20\n",
    "    for row in partition:\n",
    "        # 找到索引与IDF值并进行排序\n",
    "        _ = list(zip(row.idfFeatures.indices, row.idfFeatures.values))\n",
    "        _ = sorted(_, key=lambda x: x[1], reverse=True)\n",
    "        result = _[:TOPK]\n",
    "        for word_index, tfidf in result:\n",
    "            yield row.article_id, row.channel_id, int(word_index), round(float(tfidf), 4)\n",
    "kewords_tfidf = tfidf_res.rdd.mapPartitions(func).toDF(['article_id', 'channel_id', 'index', 'weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----+---------+\n",
      "|article_id|channel_id|index|  weights|\n",
      "+----------+----------+-----+---------+\n",
      "|     12237|        18|    0|1626.3407|\n",
      "|     12237|        18| 1115| 561.4683|\n",
      "|     12237|        18|  848| 458.1074|\n",
      "|     12237|        18|  296| 285.3019|\n",
      "|     12237|        18| 1090| 175.9988|\n",
      "|     12237|        18|  911| 175.8358|\n",
      "|     12237|        18|  909| 169.7768|\n",
      "|     12237|        18| 1221| 168.8114|\n",
      "|     12237|        18|  350| 167.0493|\n",
      "|     12237|        18| 1473| 166.4656|\n",
      "|     12237|        18|  101|  158.973|\n",
      "|     12237|        18| 1381| 157.2973|\n",
      "|     12237|        18|  931|  152.294|\n",
      "|     12237|        18|   38| 145.3656|\n",
      "|     12237|        18|    4| 119.3862|\n",
      "|     12237|        18|  262| 119.3606|\n",
      "|     12237|        18|  159|  98.8927|\n",
      "|     12237|        18|  333|  94.1979|\n",
      "|     12237|        18| 1203|  89.5603|\n",
      "|     12237|        18|  408|  86.6918|\n",
      "+----------+----------+-----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kewords_tfidf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用keywordsIndex = ktt.spark.sql(\"select keyword, index idx from idf_keywords_values\")中标，知道索引对应的词\n",
    "idf_keywords_values = oa.spark.sql(\"select keyword, index idx from idf_keywords_values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------+-------+\n",
      "|article_id|channel_id|keyword|weights|\n",
      "+----------+----------+-------+-------+\n",
      "|     14450|        18|    var|  1.332|\n",
      "|     14509|        18|    var|11.9878|\n",
      "|     14541|        18|    var|10.6558|\n",
      "|     14564|        18|    var|14.6517|\n",
      "|     14569|        18|    var|10.6558|\n",
      "|     14597|        18|    var| 3.9959|\n",
      "|     14730|        18|    var|13.3198|\n",
      "|     14841|        18|    var|13.3198|\n",
      "|     14864|        18|    var| 3.9959|\n",
      "|     14936|        18|    var|59.9389|\n",
      "|     15114|        18|    var|37.2953|\n",
      "|     15218|        18|    var| 3.9959|\n",
      "|     15258|        18|    var|27.9715|\n",
      "|     15275|        18|    var|  1.332|\n",
      "|     15364|        18|    var|65.2668|\n",
      "|     15643|        18|    var| 3.9959|\n",
      "|     15660|        18|    var|18.6477|\n",
      "|     15693|        18|    var|50.6151|\n",
      "|     15754|        18|    var| 3.9959|\n",
      "|     15757|        18|    var|37.2953|\n",
      "+----------+----------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keyword_str_tfidf = kewords_tfidf.join(idf_keywords_values, idf_keywords_values.idx==kewords_tfidf.index).select([\"article_id\", \"channel_id\", \"keyword\", \"weights\"])\n",
    "\n",
    "keyword_str_tfidf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 得到TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texrank\n",
    "# 分词\n",
    "def textrank(partition):\n",
    "    import os\n",
    "\n",
    "    import jieba\n",
    "    import jieba.analyse\n",
    "    import jieba.posseg as pseg\n",
    "    import codecs\n",
    "\n",
    "    abspath = \"/root/words\"\n",
    "\n",
    "    # 结巴加载用户词典\n",
    "    userDict_path = os.path.join(abspath, \"ITKeywords.txt\")\n",
    "    jieba.load_userdict(userDict_path)\n",
    "\n",
    "    # 停用词文本\n",
    "    stopwords_path = os.path.join(abspath, \"stopwords.txt\")\n",
    "\n",
    "    def get_stopwords_list():\n",
    "        \"\"\"返回stopwords列表\"\"\"\n",
    "        stopwords_list = [i.strip()\n",
    "                          for i in codecs.open(stopwords_path).readlines()]\n",
    "        return stopwords_list\n",
    "\n",
    "    # 所有的停用词列表\n",
    "    stopwords_list = get_stopwords_list()\n",
    "\n",
    "    class TextRank(jieba.analyse.TextRank):\n",
    "        def __init__(self, window=20, word_min_len=2):\n",
    "            super(TextRank, self).__init__()\n",
    "            self.span = window  # 窗口大小\n",
    "            self.word_min_len = word_min_len  # 单词的最小长度\n",
    "            # 要保留的词性，根据jieba github ，具体参见https://github.com/baidu/lac\n",
    "            self.pos_filt = frozenset(\n",
    "                ('n', 'x', 'eng', 'f', 's', 't', 'nr', 'ns', 'nt', \"nw\", \"nz\", \"PER\", \"LOC\", \"ORG\"))\n",
    "\n",
    "        def pairfilter(self, wp):\n",
    "            \"\"\"过滤条件，返回True或者False\"\"\"\n",
    "\n",
    "            if wp.flag == \"eng\":\n",
    "                if len(wp.word) <= 2:\n",
    "                    return False\n",
    "\n",
    "            if wp.flag in self.pos_filt and len(wp.word.strip()) >= self.word_min_len \\\n",
    "                    and wp.word.lower() not in stopwords_list:\n",
    "                return True\n",
    "    # TextRank过滤窗口大小为5，单词最小为2\n",
    "    textrank_model = TextRank(window=5, word_min_len=2)\n",
    "    allowPOS = ('n', \"x\", 'eng', 'nr', 'ns', 'nt', \"nw\", \"nz\", \"c\")\n",
    "\n",
    "    for row in partition:\n",
    "        tags = textrank_model.textrank(row.sentence, topK=20, withWeight=True, allowPOS=allowPOS, withFlag=False)\n",
    "        for tag in tags:\n",
    "            yield row.article_id, row.channel_id, tag[0], tag[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "textrank = article_data.rdd.mapPartitions(textrank).toDF([\"article_id\", \"channel_id\", \"keyword\", \"textrank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------+-------------------+\n",
      "|article_id|channel_id|keyword|           textrank|\n",
      "+----------+----------+-------+-------------------+\n",
      "|     12237|        18| crayon|                1.0|\n",
      "|     12237|        18|  class| 0.9501036070450275|\n",
      "|     12237|        18|     pa| 0.6992489821528144|\n",
      "|     12237|        18|    div|0.45287701701165306|\n",
      "|     12237|        18|     &#|0.33654037380344864|\n",
      "|     12237|        18|   line|0.20897055189510236|\n",
      "|     12237|        18|     区块|0.14429613523841756|\n",
      "|     12237|        18|    num|0.13727844489573357|\n",
      "|     12237|        18|     节点|0.10960152318431637|\n",
      "|     12237|        18| button|0.10778796016549291|\n",
      "|     12237|        18|   code|0.10613517820935363|\n",
      "|     12237|        18|striped|0.09980116915318452|\n",
      "|     12237|        18|    区块链|0.09680906050323575|\n",
      "|     12237|        18|   data|0.09083121725478936|\n",
      "|     12237|        18|     交易|0.08936496548092669|\n",
      "|     12237|        18|  chain|0.08366252481157677|\n",
      "|     12237|        18|    png| 0.0782780129807765|\n",
      "|     12237|        18|  style|0.06750688035408095|\n",
      "|     12237|        18|  block|0.06448973530115029|\n",
      "|     12237|        18| import|0.06421564606719639|\n",
      "+----------+----------+-------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textrank.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.依据TF-IDF及TextRank得到词及其权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算关键词最后的权重，Textank  * IDF\n",
    "idf = oa.spark.sql(\"select * from idf_keywords_values\")\n",
    "idf = idf.withColumnRenamed(\"keyword\", \"keyword1\")\n",
    "result = textrank.join(idf,textrank.keyword==idf.keyword1)\n",
    "keywords_res = result.withColumn(\"weights\", result.textrank * result.idf).select([\"article_id\", \"channel_id\", \"keyword\", \"weights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+-------------------+\n",
      "|article_id|channel_id| keyword|            weights|\n",
      "+----------+----------+--------+-------------------+\n",
      "|     49531|        18|    BLEU| 2.6220949820228965|\n",
      "|     15259|        18|      C#| 0.8302318750634707|\n",
      "|     16217|        18|      C#| 0.2298910720861784|\n",
      "|     16331|        18|      C#|0.28636277071116106|\n",
      "|     16344|        18|      C#| 1.0336865923547185|\n",
      "|     17360|        18|      C#| 1.2997082956979977|\n",
      "|     17802|        18|      C#|0.24716768943850292|\n",
      "|     49792|        18|      C#| 0.6959435616798894|\n",
      "|     13285|        18|      C#| 2.2848330028444113|\n",
      "|     13506|        18|      C#|   1.01260771691963|\n",
      "|     13579|        18|      C#|   1.39950622733909|\n",
      "|     13876|        18|      C#| 0.8821074765951309|\n",
      "|     18506|        18|      C#| 0.5767786169503137|\n",
      "|     19053|        18|      C#|0.30589550535607357|\n",
      "|     44577|        18|      C#| 3.9274063388273364|\n",
      "|     44660|        18|      C#|  4.035406028016797|\n",
      "|    116999|        18|      C#|  1.923742355295644|\n",
      "|    117930|        18|     CSR| 1.2710693741646675|\n",
      "|     14864|        18|Consolas| 2.3796046873042656|\n",
      "|     15773|        18|Consolas| 0.9930879755552025|\n",
      "+----------+----------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 20个Keyword，对应的权重，文章ID，channel_id\n",
    "keywords_res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_res.registerTempTable(\"temptable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_weights_list = oa.spark.sql(\"select article_id, min(channel_id) channel_id, collect_list(keyword) keywords, collect_list(weights) weights from temptable group by article_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------------------+\n",
      "|article_id|channel_id|            keywords|             weights|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "|     15237|        18|[input, TANGRAM, ...|[0.22325206546519...|\n",
      "|     17703|        18|[hljs, h2, Hannin...|[3.99268223953728...|\n",
      "|     17971|        18|[hljs, imageView2...|[3.18293838018398...|\n",
      "|     18730|        18|[hljs, jwt, 资源, 信...|[4.62965411949731...|\n",
      "|     19141|        18|[hljs, 表达式, .h, c...|[5.00926646711115...|\n",
      "|     19163|        18|[hljs, .h, code, ...|[3.64623759402293...|\n",
      "|    117936|        18|[序列, 赋值, code, 元组...|[1.10120084310549...|\n",
      "|    133164|        18|[transaction, ser...|[0.76851402647143...|\n",
      "|     13098|        18|[repr, getPrice, ...|[0.63265901177161...|\n",
      "|     14719|        18|[import, Thread, ...|[0.62073537067287...|\n",
      "|     15322|        18|[import, code, ti...|[0.27776326224116...|\n",
      "|     18295|        18|[routing, queue, ...|[1.94772357894299...|\n",
      "|    117180|        18|[import, h5, Libr...|[0.97877732359854...|\n",
      "|    118448|        18|[import, session,...|[0.74972736170973...|\n",
      "|    118628|        18|[import, code, lo...|[0.66753161028174...|\n",
      "|     49586|        18|[amp, jpg, 3d, 课程...|[0.43922767714830...|\n",
      "|    117264|        18|[amp, code, 站点, u...|[0.42350684505663...|\n",
      "|    118408|        18|[jpg, title, 迭代器,...|[2.382771245637, ...|\n",
      "|    133142|        18|[amp, 文章, imageVi...|[0.52707935232550...|\n",
      "|     15846|        18|[splitter1, Sep, ...|[1.97964769319810...|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keyword_weights_list.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_weights_to_dict(row):\n",
    "    return row.article_id, row.channel_id, dict(zip(row.keywords, row.weights))\n",
    "    \n",
    "keywords = keyword_weights_list.rdd.map(keyword_weights_to_dict).toDF(['article_id', 'channel_id', 'keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n",
      "|article_id|channel_id|            keywords|\n",
      "+----------+----------+--------------------+\n",
      "|     15237|        18|Map(pre -> 0.5349...|\n",
      "|     17703|        18|Map(函数 -> 0.79761...|\n",
      "|     17971|        18|Map(imageView2 ->...|\n",
      "|     18730|        18|Map(hljs -> 4.629...|\n",
      "|     19141|        18|Map(函数 -> 0.22260...|\n",
      "|     19163|        18|Map(对象 -> 0.20687...|\n",
      "|    117936|        18|Map(pre -> 1.4263...|\n",
      "|    133164|        18|Map(static -> 0.1...|\n",
      "|     13098|        18|Map(pre -> 0.6040...|\n",
      "|     14719|        18|Map(pre -> 0.8814...|\n",
      "|     15322|        18|Map(pre -> 0.5762...|\n",
      "|     18295|        18|Map(method -> 0.6...|\n",
      "|    117180|        18|Map(pre -> 1.7729...|\n",
      "|    118448|        18|Map(反序列化 -> 1.786...|\n",
      "|    118628|        18|Map(pre -> 1.5351...|\n",
      "|     49586|        18|Map(lightbox -> 2...|\n",
      "|    117264|        18|Map(static -> 0.4...|\n",
      "|    118408|        18|Map(对象 -> 0.88355...|\n",
      "|    133142|        18|Map(imageView2 ->...|\n",
      "|     15846|        18|Map(QSplitter -> ...|\n",
      "+----------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keywords.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.依据TF-IDF及TextRank得到主题词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sql = \"\"\"\n",
    "                select t.article_id article_id2, collect_set(t.keyword) topics from tfidf_keywords_values t\n",
    "                inner join \n",
    "                textrank_keywords_values r\n",
    "                where t.keyword=r.keyword\n",
    "                group by article_id2\n",
    "                \"\"\"\n",
    "\n",
    "article_topics = oa.spark.sql(topic_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#article_topics.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 依据词权重和主题词得到文章画像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_profile = keywords.join(article_topics, keywords.article_id==article_topics.article_id2).select([\"article_id\", \"channel_id\", \"keywords\", \"topics\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------------------+\n",
      "|article_id|channel_id|            keywords|              topics|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "|     13098|        18|Map(pre -> 0.6040...|[__, object, self...|\n",
      "|     13248|        18|Map(有限元 -> 5.2929...|[npk1, eindex, 有限...|\n",
      "|     13401|        18|Map(pre -> 0.2100...|[补码, 字符串, 李白, typ...|\n",
      "|     13723|        18|Map(pre -> 2.1094...|[lis2, acc, bstr,...|\n",
      "|     14719|        18|Map(pre -> 0.8814...|[__, ctime, Sep, ...|\n",
      "|     14846|        18|Map(__ -> 2.54674...|[__, folders, fil...|\n",
      "|     15173|        18|Map(人人 -> 0.73972...|[filecookiejar, c...|\n",
      "|     15194|        18|Map(dif -> 0.7567...|[video2, display,...|\n",
      "|     15237|        18|Map(pre -> 0.5349...|[__, send, try, s...|\n",
      "|     15322|        18|Map(pre -> 0.5762...|[Pclass, replace,...|\n",
      "|     15375|        18|Map(pre -> 1.7091...|[内存地址, list2, 浅拷贝...|\n",
      "|     15432|        18|Map(模式 -> 0.44872...|[内存, 显示文件, 读后写, y...|\n",
      "|     15437|        18|Map(__ -> 0.59289...|[AB型, frac, 奥利佛, ...|\n",
      "|     15846|        18|Map(QSplitter -> ...|[__, QSplitter, s...|\n",
      "|     17499|        18|Map(task -> 0.352...|[app, 任务, task1, ...|\n",
      "|     17703|        18|Map(函数 -> 0.79761...|[weights, pltimpo...|\n",
      "|     17971|        18|Map(imageView2 ->...|[findall, compile...|\n",
      "|     17979|        18|Map(url -> 0.2644...|[cookie, eaders, ...|\n",
      "|     18147|        18|Map(imageView2 ->...|[Queue, 进程, 多进程, ...|\n",
      "|     18196|        18|Map(imageView2 ->...|[语言, 空间, ssa, 编译器...|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "article_profile.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. 词向量模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过少量数据来演示训练\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "\n",
    "w2v = Word2Vec(vectorSize=100, inputCol='words', outputCol='model', minCount=3)\n",
    "w2v_model = w2v.fit(words_df)\n",
    "w2v_model.write().overwrite().save(\"hdfs://hadoop-master:9000/headlines/models/test.word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------------------+\n",
      "|article_id|channel_id|            keywords|              topics|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "|     13098|        18|Map(pre -> 0.6040...|[__, object, self...|\n",
      "|     13248|        18|Map(有限元 -> 5.2929...|[npk1, eindex, 有限...|\n",
      "|     13401|        18|Map(pre -> 0.2100...|[补码, 字符串, 李白, 元素,...|\n",
      "|     13723|        18|Map(pre -> 2.1094...|[lis2, acc, bstr,...|\n",
      "|     14719|        18|Map(pre -> 0.8814...|[__, ctime, Sep, ...|\n",
      "|     14846|        18|Map(__ -> 2.54674...|[folders, files, ...|\n",
      "|     15173|        18|Map(人人 -> 0.73972...|[filecookiejar, c...|\n",
      "|     15194|        18|Map(dif -> 0.7567...|[video2, display,...|\n",
      "|     15237|        18|Map(pre -> 0.5349...|[send, __, try, s...|\n",
      "|     15322|        18|Map(pre -> 0.5762...|[Pclass, replace,...|\n",
      "|     15375|        18|Map(pre -> 1.7091...|[内存地址, 浅拷贝, list2...|\n",
      "|     15432|        18|Map(模式 -> 0.44872...|[内存, 显示文件, 读后写, y...|\n",
      "|     15437|        18|Map(__ -> 0.59289...|[AB型, frac, 奥利佛, ...|\n",
      "|     15846|        18|Map(QSplitter -> ...|[__, QSplitter, s...|\n",
      "|     17499|        18|Map(task -> 0.352...|[app, 任务, task1, ...|\n",
      "|     17703|        18|Map(函数 -> 0.79761...|[weights, pltimpo...|\n",
      "|     17971|        18|Map(imageView2 ->...|[findall, compile...|\n",
      "|     17979|        18|Map(url -> 0.2644...|[cookie, eaders, ...|\n",
      "|     18147|        18|Map(imageView2 ->...|[Queue, 进程, 多进程, ...|\n",
      "|     18196|        18|Map(imageView2 ->...|[语言, 空间, ssa, 编译器...|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "article_profile.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 求出增量文章的词向量，增量文章 一共10篇文章\n",
    "# 1、加载某个频道模型，得到每个词的向量\n",
    "from pyspark.ml.feature import Word2VecModel\n",
    "\n",
    "word_vec = Word2VecModel.load(\"hdfs://hadoop-master:9000/headlines/models/test.word2vec\")\n",
    "vectors = word_vec.getVectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+\n",
      "|              word|              vector|\n",
      "+------------------+--------------------+\n",
      "|                广义|[-0.3124968707561...|\n",
      "|                钟爱|[0.03830356895923...|\n",
      "|c1c3387c24028915fc|[-0.0023575632367...|\n",
      "|          failCnt0|[0.02495069056749...|\n",
      "|       freeman1974|[-0.0393065623939...|\n",
      "|                伙伴|[-0.1904211044311...|\n",
      "|  testStationarity|[-0.0568049065768...|\n",
      "|                箭头|[0.03213853389024...|\n",
      "|        fieldsfrom|[-0.0137809459120...|\n",
      "|      RoundrobinLB|[-0.0076495949178...|\n",
      "|              COCO|[-0.0488479435443...|\n",
      "|                拜拜|[0.02235601097345...|\n",
      "|          quotient|[0.23557169735431...|\n",
      "|                货币|[-0.1088096722960...|\n",
      "|                人物|[0.13329826295375...|\n",
      "|               wsy|[-0.0372068472206...|\n",
      "|           serious|[0.06451868265867...|\n",
      "|               跨进程|[0.03020830452442...|\n",
      "|        fromParams|[0.01803738623857...|\n",
      "|        MongoDB数据库|[0.04348663613200...|\n",
      "+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectors.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 得到文章的词及权重并展开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取频道的文章画像，得到文章画像的关键词，找到这些文章关键词对应词向量\n",
    "python_article_profile = article_profile.filter('channel_id=18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------------------+\n",
      "|article_id|channel_id|            keywords|              topics|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "|     13098|        18|Map(pre -> 0.6040...|[__, object, self...|\n",
      "|     13248|        18|Map(有限元 -> 5.2929...|[npk1, eindex, 有限...|\n",
      "|     13401|        18|Map(pre -> 0.2100...|[补码, 字符串, 李白, 元素,...|\n",
      "|     13723|        18|Map(pre -> 2.1094...|[lis2, acc, bstr,...|\n",
      "|     14719|        18|Map(pre -> 0.8814...|[__, ctime, Sep, ...|\n",
      "|     14846|        18|Map(__ -> 2.54674...|[folders, __, fil...|\n",
      "|     15173|        18|Map(人人 -> 0.73972...|[filecookiejar, c...|\n",
      "|     15194|        18|Map(dif -> 0.7567...|[video2, display,...|\n",
      "|     15237|        18|Map(pre -> 0.5349...|[__, send, try, s...|\n",
      "|     15322|        18|Map(pre -> 0.5762...|[Pclass, replace,...|\n",
      "|     15375|        18|Map(pre -> 1.7091...|[内存地址, 浅拷贝, list2...|\n",
      "|     15432|        18|Map(模式 -> 0.44872...|[内存, 显示文件, 读后写, y...|\n",
      "|     15437|        18|Map(__ -> 0.59289...|[AB型, frac, 奥利佛, ...|\n",
      "|     15846|        18|Map(QSplitter -> ...|[__, QSplitter, s...|\n",
      "|     17499|        18|Map(task -> 0.352...|[app, 任务, task1, ...|\n",
      "|     17703|        18|Map(函数 -> 0.79761...|[pltimport, weigh...|\n",
      "|     17971|        18|Map(imageView2 ->...|[findall, compile...|\n",
      "|     17979|        18|Map(url -> 0.2644...|[cookie, eaders, ...|\n",
      "|     18147|        18|Map(imageView2 ->...|[Queue, 进程, 多进程, ...|\n",
      "|     18196|        18|Map(imageView2 ->...|[语言, 空间, ssa, 编译器...|\n",
      "+----------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "python_article_profile.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+-------------------+\n",
      "|article_id|channel_id| keyword|             weight|\n",
      "+----------+----------+--------+-------------------+\n",
      "|     13098|        18|      __| 2.5401122038114203|\n",
      "|     13098|        18|    repr| 0.6326590117716192|\n",
      "|     13098|        18|     pre| 0.6040062287555379|\n",
      "|     13098|        18|      属性|0.23645924932468856|\n",
      "|     13098|        18|    code| 0.9531379029975557|\n",
      "|     13098|        18|     def| 0.5063435861497416|\n",
      "|     13098|        18|      定义| 0.1554380122061322|\n",
      "|     13098|        18|   color| 1.1337936117177925|\n",
      "|     13098|        18| Student| 0.5033771372284416|\n",
      "|     13098|        18|getPrice| 0.7404427038950527|\n",
      "|     13098|        18|      方法|0.08080845613717194|\n",
      "|     13098|        18|     div| 0.3434819820586186|\n",
      "|     13098|        18|     str|0.35999033790156054|\n",
      "|     13098|        18|      pa| 0.6651385256756351|\n",
      "|     13098|        18|   slots| 0.6992789472129189|\n",
      "|     13098|        18| cnblogs|0.33926586102013295|\n",
      "|     13098|        18|      函数|0.15015578405898256|\n",
      "|     13098|        18|   style| 2.4777013955852873|\n",
      "|     13098|        18|      &#| 0.4911011561534254|\n",
      "|     13098|        18|   class|0.28891320463243075|\n",
      "+----------+----------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 将文章画像的字典， 词语与权重 进行展开\n",
    "python_article_profile.registerTempTable('profile')\n",
    "\n",
    "_articlekeywordsweight = oa.spark.sql(\"select article_id,  channel_id, keyword, weight from profile LATERAL VIEW explode(keywords) AS keyword, weight\")\n",
    "\n",
    "\n",
    "_articlekeywordsweight.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 合并词向量和 文章词及权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将文章词权重 和 词向量 模型 进行 inner 合并\n",
    "article_keyword_vec_weights = _articlekeywordsweight.join(vectors, vectors.word==_articlekeywordsweight.keyword, \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+-------------------+--------+--------------------+\n",
      "|article_id|channel_id| keyword|             weight|    word|              vector|\n",
      "+----------+----------+--------+-------------------+--------+--------------------+\n",
      "|     13098|        18|      __| 2.5401122038114203|      __|[-0.6546941995620...|\n",
      "|     13098|        18|    repr| 0.6326590117716192|    repr|[-0.4608801603317...|\n",
      "|     13098|        18|     pre| 0.6040062287555379|     pre|[-0.1207879632711...|\n",
      "|     13098|        18|      属性|0.23645924932468856|      属性|[-0.4689875245094...|\n",
      "|     13098|        18|    code| 0.9531379029975557|    code|[0.10663777589797...|\n",
      "|     13098|        18|     def| 0.5063435861497416|     def|[-0.2050044685602...|\n",
      "|     13098|        18|      定义| 0.1554380122061322|      定义|[-0.1936927884817...|\n",
      "|     13098|        18|   color| 1.1337936117177925|   color|[-0.2678930759429...|\n",
      "|     13098|        18| Student| 0.5033771372284416| Student|[-0.3861369490623...|\n",
      "|     13098|        18|getPrice| 0.7404427038950527|getPrice|[0.09135685861110...|\n",
      "|     13098|        18|      方法|0.08080845613717194|      方法|[-0.2487207353115...|\n",
      "|     13098|        18|     div| 0.3434819820586186|     div|[0.41308197379112...|\n",
      "|     13098|        18|     str|0.35999033790156054|     str|[-0.0163050387054...|\n",
      "|     13098|        18|      pa| 0.6651385256756351|      pa|[0.03578713536262...|\n",
      "|     13098|        18|   slots| 0.6992789472129189|   slots|[-0.6711847782135...|\n",
      "|     13098|        18| cnblogs|0.33926586102013295| cnblogs|[0.29950669407844...|\n",
      "|     13098|        18|      函数|0.15015578405898256|      函数|[-0.1913491636514...|\n",
      "|     13098|        18|   style| 2.4777013955852873|   style|[-0.0647300332784...|\n",
      "|     13098|        18|      &#| 0.4911011561534254|      &#|[-0.0725544914603...|\n",
      "|     13098|        18|   class|0.28891320463243075|   class|[-0.2181045114994...|\n",
      "+----------+----------+--------+-------------------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "article_keyword_vec_weights.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 文章向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到文章向量\n",
    "article_keyword_vec_weights.registerTempTable(\"temptable\")\n",
    "\n",
    "def func(row):\n",
    "    x = 0\n",
    "    for v in row.vectors:\n",
    "        x += v\n",
    "        \n",
    "    return row.article_id, row.channel_id, x / len(row.vectors)\n",
    "\n",
    "article_vector = oa.spark.sql(\"select article_id, min(channel_id) channel_id, collect_set(vector) vectors from temptable group by article_id\").rdd.map(func).toDF(['article_id', 'channel_id', 'articlevector'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n",
      "|article_id|channel_id|       articlevector|\n",
      "+----------+----------+--------------------+\n",
      "|     13098|        18|[-0.1647327722050...|\n",
      "|     13248|        18|[-0.0209909798577...|\n",
      "|     13401|        18|[-0.1170251129660...|\n",
      "|     13723|        18|[-0.0636651790235...|\n",
      "|     14719|        18|[-0.1332618249114...|\n",
      "|     14846|        18|[-0.0216992553789...|\n",
      "|     15173|        18|[-0.0235749806277...|\n",
      "|     15194|        18|[0.10394728556275...|\n",
      "|     15237|        18|[0.19160119506220...|\n",
      "|     15322|        18|[-0.0103950041934...|\n",
      "|     15375|        18|[-0.1530114244669...|\n",
      "|     15432|        18|[-0.0594050147570...|\n",
      "|     15437|        18|[-0.1329826050273...|\n",
      "|     15846|        18|[0.07257945776769...|\n",
      "|     17499|        18|[0.05329569820314...|\n",
      "|     17703|        18|[0.00514154327347...|\n",
      "|     17971|        18|[-0.0809452034729...|\n",
      "|     17979|        18|[0.01235814888625...|\n",
      "|     18147|        18|[-0.1417260870435...|\n",
      "|     18196|        18|[-0.1467974732578...|\n",
      "+----------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "article_vector.show()\n",
    "# article_vector.write.insertInto(\"article_vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.根据文章向量计算文章相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "def _array_to_vector(row):\n",
    "    return row.article_id, Vectors.dense(row.articlevector)\n",
    "\n",
    "train = article_vector.rdd.map(_array_to_vector).toDF(['article_id', 'article_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BRP进行fit\n",
    "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
    "\n",
    "BRP = BucketedRandomProjectionLSH(inputCol='article_vector', outputCol='hashes', numHashTables=4.0, bucketLength=10.0)\n",
    "model = BRP.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = model.approxSimilarityJoin(train, train, 2.0, distCol='EuclideanDistance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar.sort(['EuclideanDistance']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. 保存文章相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_hbase(partition):\n",
    "    import happybase\n",
    "    pool = happybase.ConnectionPool(size=3, host='hadoop-master')\n",
    "    \n",
    "    with pool.connection() as conn:\n",
    "        # 建议表的连接\n",
    "        table = conn.table('article_similar')\n",
    "        for row in partition:\n",
    "            if row.datasetA.article_id == row.datasetB.article_id:\n",
    "                pass\n",
    "            else:\n",
    "                table.put(str(row.datasetA.article_id).encode(),\n",
    "                         {\"similar:{}\".format(row.datasetB.article_id).encode(): b'%0.4f' % (row.EuclideanDistance)})\n",
    "        # 手动关闭所有的连接\n",
    "        conn.close()\n",
    "\n",
    "similar.foreachPartition(save_hbase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
